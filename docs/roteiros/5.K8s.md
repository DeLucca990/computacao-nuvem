---
title: Computação em Nuvem
author: Tiago Demay
---

# Containers e K8s

Objetivos

1. Entender os conceitos básicos sobre Contêineres e seus Orquestradores.
1. Instalar o Octavia no Openstack
1. Integrar o Openstack e o Kubernetes


Pré-requisitos:

1. Terminar o capítulo anterior (SLA,DR e IaC)
1. Realizar a leitura sobre o [Docker](https://docs.docker.com/engine/docker-overview/).
1. Realizar a leitura sobre o [Kubernetes](https://kubernetes.io/docs/concepts/).
1. Realizar a leitura do **Octavia**. [documentação](https://docs.openstack.org/octavia/latest/) e [implantação](https://docs.openstack.org/charm-guide/latest/admin/networking/load-balancing.html)
1. Realizar a leitura do [Barbican](https://docs.openstack.org/barbican/latest/).
1. Realizar a leitura dos Charms. [Vault](https://jaas.ai/vault), [Octavia](https://jaas.ai/octavia), [Barbican](https://jaas.ai/barbican).

??? info 
    **DIVISÃO DO ROTEIRO** 
    O Roteiro é dividido em 3 partes principais.

      * Entendendo tipos de implantacoes - Visão Geral
      * Adicionando Octavia (Load Balancer) na Nuvem privada(Openstack)
      * Utilizando Docker e Kubernetes

## Voce chegou a um roteiro avancado, este Roteiro envolve a resolução de problemas de implantação, esperamos que você esteja preparado, este roteiro é prototipado por você!!!!       

## TARGET

### DO INICIO DO ROTEIRO 1 ATE ONDE CHEGAMOS NO FIM DESTE ROTEIRO

![Imagem-Topologia](../assets/images/nuvem.png){width=600}

## Tipo de implantacoes

### Tradicional
Inicialmente, as organizações executavam aplicativos em servidores físicos. Os limites de recursos não podem ser definidos para aplicativos em servidores físicos, o que causa problemas de alocação de recursos. Por exemplo, se vários aplicativos estiverem sendo executados em um servidor físico, pode haver uma situação em que um aplicativo consuma mais recursos, resultando em um desempenho insatisfatório de outros aplicativos. A solução para isso é executar cada aplicativo em um servidor físico diferente. Mas isso não aumentou porque os recursos são subutilizados e é caro para as organizações manter muitos servidores físicos.

### Virtualizada

Como solução, a virtualização foi introduzida. Ele permite que você execute várias máquinas virtuais (VMs) na CPU de um único servidor físico. A virtualização permite que os aplicativos sejam isolados entre VMs e fornece um nível de segurança que as informações de um aplicativo não podem ser acessadas livremente por outro aplicativo.
A virtualização permite uma melhor utilização dos recursos em servidores físicos e uma melhor escalabilidade, pois os aplicativos podem ser facilmente adicionados ou atualizados, os custos de hardware são reduzidos e muito mais. Com a virtualização, você pode apresentar um conjunto de recursos físicos como um cluster de máquinas virtuais descartáveis.
Cada VM é uma máquina completa, executando todos os componentes, incluindo seu próprio sistema operacional, sobre hardware virtualizado.

### Conteinerizada

Os contêineres são pacotes leves do código do seu aplicativo, juntamente com dependências, como versões específicas de tempos de execução de linguagem de programação e bibliotecas necessárias para executar seus serviços de software.
Os contêineres facilitam o compartilhamento de recursos de CPU, memória, armazenamento e rede no nível dos sistemas operacionais e oferecem um mecanismo de empacotamento lógico no qual os aplicativos podem ser abstraídos do ambiente em que realmente são executados.

**Os contêineres virtualizam no nível do sistema operacional enquanto as VMs virtualizam no nível do hardware**

![Imagem-Topologia](../assets/images/container.png){width=600}


## Instalando e Configurando o Octavia (Loadbalancer para Openstack)

* No servidor Main - análise o juju status seu LoadBalancer deve ser implantado nesta infraestrutura sem causar degradação dos serviços já existentes: Faça a instalação do **Octavia** de acordo com a leitura prévia obrigatória !!!



??? DICAS
    **Dicas sobre Troubleshooting**

    Durante o processo de implantação de OpenStack, Octavia e Kubernetes, é comum que surjam problemas técnicos inesperados. Aqui estão algumas dicas para solucionar possíveis dificuldades:

    1. Problemas de Conexão no Juju
       - **Sintomas**: Erros ao tentar conectar ao controlador ou realizar deploys.
       - **Solução**: Verifique se as máquinas de infraestrutura estão acessíveis. Use o comando `juju status` para inspecionar o estado dos serviços. Reiniciar o agente do Juju com `juju reload` pode resolver problemas de conectividade.

    2. Erros ao Configurar o Octavia
       - **Sintomas**: Octavia não aparece como um recurso de load balancing no OpenStack ou falhas ao configurar relações.
       - **Solução**: Confirme que todos os pré-requisitos de rede estão configurados corretamente e que o charm Octavia está relacionado ao Neutron e ao Keystone. Use `juju debug-log --include octavia/0` para inspecionar logs específicos do Octavia.

    3. Falhas de Certificados no Octavia
       - **Sintomas**: Octavia não aceita as configurações de certificados ou falha ao gerar instâncias de load balancers.
       - **Solução**: Revise os certificados gerados, conferindo se estão nos formatos e permissões corretos. Certifique-se de que os certificados CA e os tokens do Vault estão válidos. Verifique a validade dos certificados com `openssl x509 -noout -in [certificado] -dates`.

    4. Erros ao Criar o Cluster Kubernetes
       - **Sintomas**: Kubernetes não inicia corretamente, ou não conecta ao Juju.
       - **Solução**: Verifique se o Juju está configurado para o OpenStack como Cloud Provider. Use `juju status` para identificar onde o processo falhou, e verifique logs do Kubernetes com `kubectl logs`.

??? info
    Certificados SSL (Secure Sockets Layer) são essenciais para garantir a segurança na comunicação entre servidores e clientes na web, especialmente em contextos onde os dados trafegados devem ser protegidos contra interceptações ou alterações. No caso de um load balancer como o Octavia, os certificados SSL desempenham um papel fundamental na proteção das interações entre o controlador do load balancer e as instâncias (conhecidas como amphorae) que distribuem o tráfego.

    O uso de SSL cria um "túnel" seguro, criptografando os dados transmitidos para que apenas os dispositivos autorizados consigam descriptografar e entender o conteúdo das mensagens. Isso impede que terceiros interceptem e acessem informações sensíveis ou modifiquem os dados em trânsito.

    Para o Octavia, que precisa gerenciar e monitorar as instâncias de load balancers, o SSL assegura que qualquer instrução enviada ao load balancer seja legítima e provenha do controlador autorizado. Assim, SSL ajuda a garantir que o tráfego balanceado entre as máquinas do OpenStack seja confiável e imune a ataques de "man-in-the-middle" (interceptação), oferecendo um nível robusto de segurança e autenticidade para toda a arquitetura da nuvem.

Ainda no Servidor *main*, vamos aumentar alguns limites:

`openstack quota set --cores 100 [ID do Projeto]`

`openstack quota set --instances 100 [ID do Projeto]`


No capítulo 3, foi realizada a implantação do Openstack no hardware disponível. Além de VMs, o Openstack consegue também manipular containers, tal qual o MaaS e o Juju. Contudo o grande problema é que não basta apenas criar e destruir um container, é preciso administrar uma complexa arquitetura, monitorando e controlando um conjunto de containers que representam uma implantação de um sistema.


## WebServer 

* Criar uma instância m1.small com IP público no Openstack, nomea-la como **juju-openstack-web-server**
* Adicionar um Security Group novo a esta instancia (não utilizar o default)
* Acessar a instancia criada
* Vamos criar um WebServer em NodeJS
* Criar o arquivo ~/hello-node/server.js

```
#!/usr/bin/env nodejs

var http = require('http');
var os = require('os');

var handleRequest = function(request, response) {
    console.log('Received request for URL: ' + request.url);
    response.writeHead(200);
    response.end('{ "host": ' + os.hostname() + ', "message": "Hello World!"}');
};

var www = http.createServer(handleRequest);
www.listen(8080);
console.log('Server running at http://localhost:8080/');

```

* Testar o WebServer rodando localmente no terminal.

```
sudo apt install nodejs
./server.js
```

!!! exercise
    CheckPoint-1 WebServer


    1. De um print das Telas abaixo:
      1. Da aba network *topology* no **OpenStack**.
      1. Das regras do Security Group utilizado.
      1. Da Aba do navegador com o WebServer Rodando.




# Instalar o Docker na instancia

Arquitetura Docker :exclamation:

![Imagem-Topologia](../assets/images/docker.png){width=600}


```
sudo apt-get update
sudo apt install build-essential apt-transport-https curl
curl -fsSL https://get.docker.com | sh -
sudo usermod -aG docker $USER
newgrp docker
docker version
docker run hello-world

```


* Criar uma um arquivo ~/hello-node/Dockerfile que dará origem ao container

```
FROM node:6.9.2
EXPOSE 8080
COPY server.js .
CMD node server.js
```

* Montar a imagem local (Cria um container com esta aplicacao webserver)

`docker build -t hello-node:v1 ./hello-node/`

* Rodar o container com a imagem criada.

`docker container run hello-node:v1`


!!! exercise
    CheckPoint-2 Docker

    1. De um print das Telas abaixo:
      1. WebServer Rodando no navegador.
      1. Saída do comando (docker images ls)
      1. Saída do comando (docker container ls)


## Docker Hub
* Caso não tenha ainda, criar individualmente um login (usuário) na https://hub.docker.com/

• Fazer o login no Docker
• Aplicar a tag na imagem e dar o push do Docker Hub
• Para mais detalhes `docker --help`


### Kubernetes aka k8s - iremos implatantar um conjunto de ferramentas e softwares que juntos forma o Kubernertes.

![Imagem-Topologia](../assets/images/kubernetes.png){width=600}

* Para facilitar o deploy do Kubernetes vamos utilizar uma **"velha conhecida"**. 

### Deja-vu (Juju Reborn)

O Dashboard do Openstack possui alguns termos (region, instance type, security group, etc) que são semelhantes ao da AWS. Como visto anteriormente, Juju consegue operar sobre Public Cloud, Private Cloud, Bare-metal e Container. Para o setup ficar completo, agora vamos utilizar o Juju sobre o **Openstack**.


??? dicas
    [Documentacao - adicionar Openstack como cloud](https://juju.is/docs/olm/openstack)  
    [Documentacao - adicionar integrador obrigatório](https://ubuntu.com/kubernetes/docs/openstack-integration)  
    [Bundle modificado do Kubernetes-core](https://github.com/Insper/computacao-nuvem/blob/main/docs/bundle.yaml)  

* Acesse a instância m1.tiny criada no início do roteiro.
* Fazer a instalação do Juju.
* Adicione o Openstack como Cloud Provider no Juju.
* Fazer o deploy do **Kubernetes-core**



* Instalar kubectl no cliente via snap.
`sudo snap install kubectl --classic`

* Verificar a configuração do Kubernetes via kubectl
`kubectl cluster-info`

* Caso tenha problemas ver: [documentacao-kubernetes](https://ubuntu.com/kubernetes/docs/operations)
* Configurar o kubectl proxy para utilização externa na porta 8080.
* Acessar o Dashboard.


## Fazendo um Deploy
* Fazer o deploy da imagem docker criada na sessão anterior

`kubectl run hello-node --image=[user]/hello-node:v1 --port=8080`

* Verificar no terminal: `kubectl get all`
* Verificar o deploy status no Dashboard
* Expandir o deploy para 5 réplicas do pod


!!! exercise
    CheckPoint-3 Dashboard Kubernetes

    1. De um print das Telas abaixo:
      1. Do dashboard Kubernetes com as 5 replicas


## Acessando o Deploy - entregando a aplicação para seu cliente

Criar um serviço que irá expor o deploy

### Alternativa I - ClusterIP com Ingress

`kubectl expose deployment hello-node --type=ClusterIP`

* Criar o arquivo ingress.yaml

```
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: hello-node-ingress
spec:
  rules:
  - host: hello-node.[ip do kubernetes-worker].xip.io
    http:
      paths:
      - path: /
        backend:
          serviceName: hello-node
          servicePort: 8080

```
* Aplicar arquivo ingress ao K8s

`kubectl create -f ingress.yaml`

!!! exercise
    CheckPoint-4 Expose Service

    1. De um print das Telas abaixo:
      1. Do comando  ->  kubectl get all




### Alternativa II - NodePort

`kubectl expose deployment hello-node --type=NodePort`

* Verificar qual porta foi designada e liberar o security group do worker

`juju run --unit kubernetes-worker/[# worker] "open-port [porta]"`


!!! exercise
    CheckPoint-4 Acessar o deploy

    1. De um print das Telas abaixo:
      1. Do comando  ->  kubectl get all
      1. WebServer Rodando no navegador utilizando a porta aberta.



## Alterando o deploy

* Alterar o arquivo server.js
* Montar uma nova imagem com tag v2 e faça um push
* Fazer um deploy de um pod de testes
* Testar as alterações
* Fazer a implantação imediata em produção:

`kubectl set image deployment/hello-node hello-node=[user]/hello-node:v2`


!!! exercise
    CheckPoint-5 Modificacao

    1. De um print das Telas abaixo:
      1. Do comando  ->  kubectl get all
      1. WebServer modificado Rodando no navegador utilizando a porta aberta.


# Dinâmica Final: Utilizando o Load Balancer Octavia para o Serviço em Kubernetes

## Objetivo
Distribuir o tráfego de entrada entre as réplicas do serviço **hello-node** em Kubernetes, utilizando o load balancer Octavia para assegurar que o tráfego seja balanceado e que o serviço esteja disponível mesmo que alguma réplica falhe.

## Pré-requisitos
- Cluster Kubernetes em execução, com o serviço `hello-node` rodando com 5 réplicas.
- Configuração e validação do Octavia como load balancer no OpenStack, com certificados SSL ativos.
- Acesso à instância com Kubernetes para rodar os comandos.

## Passos

1. **Configuração do Serviço para o Load Balancer**
   - Altere o tipo de exposição do serviço `hello-node` no Kubernetes para **LoadBalancer**. Esse tipo permite que o Kubernetes provisione automaticamente um balanceador de carga com Octavia, redirecionando o tráfego para as réplicas do serviço.

   - No arquivo de configuração do serviço, modifique a seção `type` para:
     ```yaml
     apiVersion: v1
     kind: Service
     metadata:
       name: hello-node
       labels:
         app: hello-node
     spec:
       type: LoadBalancer
       ports:
       - port: 8080
         targetPort: 8080
       selector:
         app: hello-node
     ```

2. **Aplicação do Serviço**
   - Aplique a configuração atualizada com o comando:
     ```bash
     kubectl apply -f hello-node-service.yaml
     ```

3. **Validação do Load Balancer**
   - Verifique se o load balancer foi criado e se está direcionando o tráfego para as réplicas do serviço. Isso pode ser feito com o comando:
     ```bash
     kubectl get svc hello-node
     ```
   - Este comando mostrará o endereço IP externo atribuído pelo load balancer ao serviço `hello-node`. Anote esse IP, pois ele será utilizado para acessar o serviço.

4. **Teste do Balanceamento de Carga**
   - No navegador ou com `curl`, acesse o IP externo do load balancer para validar o balanceamento:
     ```bash
     curl http://[external-ip]:8080
     ```
   - Execute esse comando várias vezes ou atualize o navegador para observar como o load balancer distribui as requisições entre as réplicas. Você deve notar que as respostas vêm de diferentes réplicas do `hello-node`, indicando que o balanceamento está funcionando.

!!! exercise
    CheckPoint-6 Docker
    
    - **Objetivo**: Garantir que o serviço esteja acessível via load balancer e que o   tráfego seja distribuído uniformemente entre as réplicas. **Tarefas**:

      - Dê um print da aba do navegador mostrando o serviço rodando pelo IP externo do load balancer.

      - Verifique o balanceamento de carga acessando o IP externo múltiplas vezes e observe as respostas dos diferentes hosts.

      - Confirme que o serviço é resiliente: force a remoção de uma réplica (`kubectl delete pod [pod-name]`) e observe o load balancer direcionar o tráfego às réplicas restantes, tire prints desta etapa.

---

## Reflexão
Essa dinâmica mostra como o load balancer Octavia integra-se ao Kubernetes para distribuir o tráfego automaticamente, suportando o serviço `hello-node` e garantindo alta disponibilidade. Após concluir essa etapa, você terá implantado um serviço com balanceamento de carga, aplicando as boas práticas de exposição e resiliência de sistemas distribuídos.


## **Conclusão:** *SOMENTE PARA PENSAR* :exclamation: :exclamation: :exclamation:

Você desempenhou uma implantação em tempo real usando Kubernetes e DockerHub. Como seria uma arquitetura de Continuous Integration/Continuous Delivery (CI/CD) real utilizando Kubernetes?